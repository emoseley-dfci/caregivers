{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"label-studio_JSON_parse.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"uDujNeEHBbg5","colab_type":"text"},"source":["## Caregivers Study\n","#### Parsing label-studio JSON output\n","\n","Note: if unzipping label-studio_annotations.zip results in a `__MACOSX` file, use `yes | sudo rm -r __MACOSX/` to make it disappear."]},{"cell_type":"markdown","metadata":{"id":"Us1VnUGSBbg6","colab_type":"text"},"source":["#### Library Imports"]},{"cell_type":"code","metadata":{"id":"juhMYsLJBbg7","colab_type":"code","colab":{}},"source":["import os\n","import pandas as pd\n","import json\n","\n","## Feels like overdoing it, but import regex for a filename string search\n","import re\n","\n","## For checking if iterable\n","from collections.abc import Iterable\n","\n","## For unlisting a list of list (removing nesting)\n","from itertools import chain\n","\n","## Where am I?\n","## print(os.getcwd())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qutbytofBbg-","colab_type":"text"},"source":["## Read in Data"]},{"cell_type":"code","metadata":{"id":"g2P7GqQ0Bbg_","colab_type":"code","colab":{}},"source":["file_list = []\n","for root, dirs, files in os.walk(\"./data/label-studio_annotations/\"):\n","    for filename in files:\n","        file_list.append(filename)\n","        \n","len(file_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0UWgM9KBbhB","colab_type":"code","colab":{}},"source":["def parse_json(list_of_files):\n","    ## Create dummy data frame for filling\n","    final_res = pd.DataFrame([[0]*8], columns = ['id', 'type', 'file_id', 'note_text', 'last_index', 'label_var', 'first_index', 'text_string'])\n","\n","    for file_name in list_of_files:\n","        ## Test with a file known to have multiple annotations\n","        dat = json.load(open(\"./data/label-studio_annotations/\"+file_name)) \n","\n","        ## Once loaded, convert to data frame reading as json. Note: `json.dumps` is json encoder/decoder\n","        res = pd.read_json(json.dumps(dat['completions'][0]['result']) , orient='')\n","\n","        ## Look for annotation id to know if necessary to scope in\n","        if \"id\" in res:\n","            \n","            ## Add file_id while we're in the neighborhood...\n","            res['file_id'] = [re.compile(r'\\d+').search(dat['task_path']).group(0) + \".json\"]*(len(res.index) if len(res.index) is not 0 else 1)\n","            ## Add note_text while we're here... \n","            res['note_text'] = [dat['data']['text']]*(len(res.index) if len(res.index) is not 0 else 1)\n","            \n","            ## Create temporary variables for storing things...\n","            tmp = []\n","            tmp_full = []\n","            \n","            for nm in res['value']:\n","                \n","                ## Check if nm is empty.. unusual but happens with 353.json...\n","                if isinstance(nm, Iterable):\n","                    for i in nm:\n","                        #print(\"tmp_i:\", nm[i])\n","                        \n","                        ## Append the observation element-wise\n","                        tmp.append(nm[i])\n","                \n","                ## Append the entry to tmp_full...\n","                tmp_full.append(tmp)\n","                \n","                ## Empty tmp for refilling..\n","                tmp = []\n","            \n","            ## Create data frame from these data\n","            new_df = pd.DataFrame(tmp_full, columns = ['last_index', 'label_var', 'first_index', 'text_string'])\n","            \n","            ## Add ID index for joining\n","            new_df['id'] = res['id']\n","            \n","            ## join on id\n","            new_df = pd.merge(res, new_df, left_on='id', right_on='id', how='left')\n","            \n","            ## Clean unnecessary columns\n","            new_df = new_df.drop([\"from_name\", \"type\", \"source\", \"to_name\", \"value\"], axis=1)\n","            \n","        else:\n","            \n","            ## Add file_id while we're in the neighborhood...\n","            res['file_id'] = [re.compile(r'\\d+').search(dat['task_path']).group(0) + \".json\"]*(len(res.index) if len(res.index) is not 0 else 1)\n","            \n","            ## Add note_text while we're here... \n","            res['note_text'] = [dat['data']['text']]*(len(res.index) if len(res.index) is not 0 else 1)\n","            \n","            ## Ensure there is id column for join\n","            res['id'] = 0\n","            \n","            ## Create dummy variables\n","            tmp = [0]*4\n","            \n","            ## Label them\n","            new_df = pd.DataFrame([tmp], columns = ['last_index', 'label_var', 'first_index', 'text_string'])\n","            \n","            ## Index to join\n","            new_df['id'] = 0\n","            \n","            ## Join\n","            new_df = pd.merge(res, new_df, how = 'left')\n","\n","        ## Concatenate\n","        final_res = pd.concat([final_res, new_df], sort = False)\n","    \n","    ## Clean data before returning\n","    ## Unlist label_var\n","    final_res['label_var'] = list(chain.from_iterable(final_res['label_var'].str))\n","    \n","    ## Remove from_id, to_id, type for now..\n","    final_res = final_res.drop([\"from_id\", \"to_id\", 'type'], axis=1)\n","    \n","    ## Remove first observtion (template) from data frame\n","    ## Label-based deletion-- empty file ID...\n","    ## Reset index to file ID\n","    final_res = final_res.set_index(\"file_id\").drop(0, axis = 0) # Delete all rows with label 0?\n","\n","    return(final_res)\n","\n","dat = parse_json(file_list)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CLBS1m56BbhF","colab_type":"text"},"source":["## Checking Sanity and Writing"]},{"cell_type":"code","metadata":{"id":"fuuWupfBBbhG","colab_type":"code","colab":{}},"source":["dat.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2A7-_ulKBbhJ","colab_type":"code","colab":{}},"source":["dat.groupby([\"label_var\"]).size().reset_index(name=\"Count\").sort_values(by = \"Count\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"viBPbVpcBbhL","colab_type":"code","colab":{}},"source":["## Write\n","dat.to_csv(\"./data/caregivers_annotations19May2020.csv\")"],"execution_count":0,"outputs":[]}]}